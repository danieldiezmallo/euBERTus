{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_training_ModelForLM.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python379jvsc74a57bd05e6813dbf69670d6d3886595d9cfd7f636152ce64500f8f1b519576bcad72771","display_name":"Python 3.7.9 64-bit ('.pyvenv': venv)"},"accelerator":"GPU","metadata":{"interpreter":{"hash":"5e6813dbf69670d6d3886595d9cfd7f636152ce64500f8f1b519576bcad72771"}}},"cells":[{"cell_type":"code","metadata":{"id":"5duRggBRZKvP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619470532162,"user_tz":-120,"elapsed":13604,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"9ee5099c-2223-43ca-babe-f925d5ae77e0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/tfm_code/03 Training\n","%pwd\n","# Install `transformers` from master\n","!pip install transformers==4.5.1\n","# !pip install git+https://github.com/huggingface/transformers\n","!pip install torch\n","!pip install sklearn\n","# transformers version at notebook update --- 2.11.0\n","# tokenizers version at notebook update --- 0.8.0rc1"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/tfm_code/03 Training\n","Requirement already satisfied: transformers==4.5.1 in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (0.0.45)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (0.10.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.1) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.1) (3.7.4.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WQpUC_CDhnWW"},"source":["## 1. Load the base models and the tokenizers\n"]},{"cell_type":"code","metadata":{"id":"kD140sFjh0LQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619470532500,"user_tz":-120,"elapsed":13936,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"785d1809-40de-4ef2-9a3a-2a38ae714754"},"source":["# Check that we have a GPU\n","!nvidia-smi"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Mon Apr 26 20:55:32 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   75C    P0    34W /  70W |   1784MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VNZZs-r6iKAV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619470532501,"user_tz":-120,"elapsed":13932,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"3b6cfb6c-5565-49e8-ee2b-c9ec4dbf10e7"},"source":["# Check that PyTorch sees it\n","import torch\n","torch.cuda.is_available()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"_dR8Jv1Dy1ya"},"source":["### Model checkpoint"]},{"cell_type":"code","metadata":{"id":"3WJP178yy0yh","executionInfo":{"status":"ok","timestamp":1619470532503,"user_tz":-120,"elapsed":13933,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}}},"source":["# Select the model baseline to perform the transfer learning from\n","model_checkpoint = 'roberta-base'"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yAwQ82JiE5pi"},"source":["### Tokenizer"]},{"cell_type":"code","metadata":{"id":"4keFBUjQFOD1","executionInfo":{"status":"ok","timestamp":1619470532699,"user_tz":-120,"elapsed":14123,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}}},"source":["from transformers import RobertaTokenizer\n","tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6yNCw-3hFv9h"},"source":["### Model\n","Finally let's initialize our model. We are looking to train from a pretrained model"]},{"cell_type":"code","metadata":{"id":"BzMqR-dzF4Ro","executionInfo":{"status":"ok","timestamp":1619470541422,"user_tz":-120,"elapsed":22840,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}}},"source":["from transformers import RobertaForMaskedLM\n","model = RobertaForMaskedLM.from_pretrained(model_checkpoint)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"jU6JhBSTKiaM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619470541429,"user_tz":-120,"elapsed":22841,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"ab6c983c-e6c5-41e7-e439-b5da1da4edda"},"source":["model.num_parameters()\n","# => 84 million parameters"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["124697433"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"ri2BIQKqjfHm"},"source":["## 2. Model training"]},{"cell_type":"markdown","metadata":{"id":"5mNFxHtLzylq"},"source":["### 2.1 Define a grid search function for the training\n","\n","Finally, in order to perform the training, a grid search function that allows random search is created. The functions does the following steps:\n","* It finds all possible combinations of parameters among the parameters grid\n","* Then, if a maximum number of fits is provided, it selects n_combinations random parameter combinations from the total list\n","* It creates a directory to store the temporary trained models so they don't have to be loaded in memory\n","* It splits the data into train and validations sets\n","* Then, for every parameter combination in the list:\n","    * It creates a transformers.Trainer object with a transfomers.TrainingArguments, that is created from the parameter combination dictionary, the baseline model, the datacollator to created the training batches by masking random tokens in the training set\n","    * It trains the model\n","    * It evaluates the perplexity of the model on the validation set\n","    * It saves the score and the parameters used in a list\n","    * It writes the model to disk\n","* After all the models are trained, it finds the one with the lowest perplexity\n","* It moves the model to the output folder\n","* Finally, it returns all the models and perplexitys cores"]},{"cell_type":"code","metadata":{"id":"3aNSMwex45B8","executionInfo":{"status":"ok","timestamp":1619470541432,"user_tz":-120,"elapsed":22844,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}}},"source":["from transformers import Trainer, TrainingArguments\n","import time\n","from itertools import product\n","from sklearn.model_selection import train_test_split\n","import math\n","import os\n","from random import sample\n","from shutil import rmtree, move\n","def grid_search_for_language_modeling(baseline_model=None, param_grid={}, n_combinations=None, X=None, data_collator=None, validation_size=0.15, random_state=42, model_name='model', out_dir='models/', tmp_dir='grid_search/'): \n","    \"\"\"\n","    Performs grid search over a grid of parameters for an ML model and another grid of parameters for a function applied to training data in order to augment it\n","    It uses a custom cross validation function that only applies the function to the training data and validates on clean data\n","    -------------------------------------------------------------------------------\n","    Parameters:\n","        - model: scikit-learn like model\n","        - model_grid: dictionary of parameters to perform gird search on the _model\n","        - X (dataframe): train data (np.array)\n","        - validation_size\n","\n","    Returns:\n","        - best_model: a dictionaty that contains the results with the best model found by performing the grid search over the _model and _function\n","            + _best_model'\n","            + _best_model_params\n","            + _best_function_params\n","            + _best_score\n","    \"\"\"\n","    # Get all combinations of parameters in grid\n","    keys, values = zip(*param_grid.items())\n","    param_combinations_list = [dict(zip(keys, v)) for v in product(*values)]\n","\n","    # If a max number of combinations is provided then n_combinations random param combinations are selected from the list\n","    if n_combinations:\n","        param_combinations_list = sample(param_combinations_list, n_combinations)\n","    total_fits = len(param_combinations_list)\n","    model_params, scores = [], []\n","\n","    # Create directory to save temporary models\n","    if os.path.isdir(tmp_dir):\n","        rmtree(tmp_dir)\n","    os.makedirs(tmp_dir)\n","\n","    # Divide the dataset for validation\n","    X_train, X_test = train_test_split(X, test_size=validation_size, random_state=random_state)\n","\n","    # Start grid search\n","    start = time.time() # Get initial time of training\n","    print(f'- Starting grid search, totalling {total_fits} jobs -')\n","    for param_combination in param_combinations_list:\n","\n","        # Instantiate a model with the given param combination in the iteration\n","        print(f'  - Training model {param_combination}')\n","        training_args = TrainingArguments(**param_combination) # Unpacking the param grid\n","        trainer = Trainer(\n","                            model=baseline_model,\n","                            args=training_args,\n","                            train_dataset=X_train,\n","                            eval_dataset=X_test,\n","                            data_collator=data_collator,\n","                        )\n","        # Train the model\n","        trainer.train()\n","\n","        # Save the model\n","        trainer.save_model(f'{tmp_dir}/{len(os.listdir(tmp_dir))}')\n","\n","        # Evaluate performance\n","        eval_results = trainer.evaluate()\n","        model_score = math.exp(eval_results['eval_loss'])\n","\n","        model_params.append(param_combination)\n","        scores.append(model_score)\n","\n","        elapsed_time = time.time() - start\n","        print(f'------ - Perplexity: {model_score:.2f} | Fitted {len(scores)} jobs out of {total_fits}. Elapsed {time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))} ------') \n","            \n","    elapsed_time = time.time() - start\n","    print('--- Ending grid search, totalling {} jobs. Elapsed {} ---'.format(total_fits, time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))) \n","    \n","    # Get index og the model with the best score\n","    best_index = scores.index(min(scores))\n","    \n","    # Move model to output_dir\n","    os.rename(f'{tmp_dir}/{best_index}', f'{tmp_dir}/{model_name}')\n","\n","    # Remove the model in the output dir\n","    if os.path.isdir(f'{out_dir}/{model_name}'):\n","        rmtree(f'{out_dir}/{model_name}')\n","    \n","    # Move the contents of the new best model to the output dir\n","    move(f'{tmp_dir}/{model_name}', f'{out_dir}/{model_name}')\n","    # Remove working dir\n","    rmtree(tmp_dir)\n","\n","    # Return the best params and score in a dict\n","    return model_params, scores"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jBtUHRMliOLM"},"source":["### 2.2 Model training on European COVID texts\n"]},{"cell_type":"markdown","metadata":{"id":"rY5hwSn4zsOy"},"source":["#### Dataset build\n","\n","We'll build our dataset by applying our tokenizer to our text file.\n","\n","TextDataset: reads the full input text, tokenizes it and cuts it in block_sized chunks. Then adds special tokens (here just <s> or [\"SEP\"]/[\"CLS\"])\n","\n","LineByLineTextDataset: reads each line separately, tokenizes and truncates the lines to block_size. Adds special tokens.\n","\n","use TextDataset because --line-by-line will throw away a lot of data if not used correctly."]},{"cell_type":"code","metadata":{"id":"GlvP_A-THEEl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619470541796,"user_tz":-120,"elapsed":23204,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"e0fe0c87-ad71-46c0-b42b-1b5b0d476e25"},"source":["%%time\n","from transformers import TextDataset\n","\n","dataset = TextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"../data/02_preprocessed/full_eu_text.txt\",\n","    block_size=128,\n",")\n","print(len(dataset))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["24701\n","CPU times: user 165 ms, sys: 81 ms, total: 246 ms\n","Wall time: 264 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"raCoMBu2kZ4h","executionInfo":{"status":"ok","timestamp":1619470542011,"user_tz":-120,"elapsed":23414,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"58158388-8ff4-4419-c241-35cb57b362b2"},"source":["from sklearn.model_selection import train_test_split\n","train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n","print(type(train_dataset), type(test_dataset))\n","print(len(train_dataset), len(test_dataset))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["<class 'list'> <class 'list'>\n","19760 4941\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hDLs73HcIHk5"},"source":["#### Data collator\n","[Data collators](https://huggingface.co/transformers/master/main_classes/data_collator.html) are objects that will form a batch by using a list of dataset elements as input. These elements are of the same type as the elements of train_dataset or eval_dataset. This is just a small helper that will help us batch different samples of the dataset together into an object that PyTorch knows how to perform backprop on.\n","\n","[DataCollatorForLanguageModeling](https://huggingface.co/transformers/master/main_classes/data_collator.html#datacollatorforlanguagemodeling): Data collator used for language modeling. Inputs are dynamically padded to the maximum length of a batch if they are not all of the same length.\n","\n","For best performance, this data collator should be used with a dataset having items that are dictionaries or BatchEncoding, with the \"special_tokens_mask\" key, as returned by a PreTrainedTokenizer or a PreTrainedTokenizerFast with the argument return_special_tokens_mask=True."]},{"cell_type":"code","metadata":{"id":"zTgWPa9Dipk2","executionInfo":{"status":"ok","timestamp":1619470542012,"user_tz":-120,"elapsed":23415,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}}},"source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, #The tokenizer used for encoding the data.\n","    mlm=True, #Whether or not to use masked language modeling. The labels are -100 for non-masked tokens and the value to predict for the masked token.\n","    mlm_probability=0.15 #The probability with which to (randomly) mask tokens in the input, when mlm is set to True\n",")"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QvmDL5tFzaz6"},"source":["#### Train the model using the gird search\n","First the parameters to perform the search over the training are defined"]},{"cell_type":"code","metadata":{"id":"JVBm-tO1x6Eu","executionInfo":{"status":"ok","timestamp":1619470542233,"user_tz":-120,"elapsed":23634,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}}},"source":["param_grid = dict(\n","            output_dir=[\"../data/03_models/trainer/\"],\n","            overwrite_output_dir=[True],\n","            evaluation_strategy = [\"epoch\"],\n","            num_train_epochs=[1,2],\n","            learning_rate=[2e-4, 2e-5, 2e-6],\n","            weight_decay=[0.01, 0.005],\n","            per_device_train_batch_size=[16],\n","            per_device_eval_batch_size=[64],\n","            save_steps=[10_000],\n","            save_total_limit=[1],\n","            prediction_loss_only=[True],\n","            eval_accumulation_steps=[1]\n","            )"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xg_cKG1D0M6p"},"source":["Then the model is trained"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":546},"id":"UUGRYmQU0MJM","executionInfo":{"status":"ok","timestamp":1619473779284,"user_tz":-120,"elapsed":3260679,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"fbb9b6a4-5def-4659-bbbc-3fd7bec60ea4"},"source":["eu_models_params, eu_scores = grid_search_for_language_modeling(\n","                    baseline_model=model,\n","                    param_grid=param_grid,\n","                    n_combinations=3,\n","                    X=train_dataset,\n","                    data_collator=data_collator,\n","                    model_name='eu_bert_model',\n","                    out_dir='../data/03_models/',\n","                    tmp_dir='../data/03_models/tmp/'\n","                    )\n","\n","import pickle\n","pickle.dump(eu_models_params, open('../data/03_models/eu_models_params.p', 'wb'))\n","pickle.dump(eu_scores, open('../data/03_models/eu_scores.p', 'wb'))"],"execution_count":44,"outputs":[{"output_type":"stream","text":["- Starting grid search, totalling 3 jobs -\n","  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 1, 'learning_rate': 2e-06, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1050/1050 12:59, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.068900</td>\n","      <td>1.942543</td>\n","      <td>37.439100</td>\n","      <td>79.169000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [47/47 00:37]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["------ - Perplexity: 6.93 | Fitted 1 jobs out of 3. Elapsed 00:13:41 ------\n","  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 1, 'learning_rate': 0.0002, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1050/1050 12:57, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.829500</td>\n","      <td>1.597354</td>\n","      <td>37.437900</td>\n","      <td>79.171000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [47/47 00:37]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["------ - Perplexity: 4.97 | Fitted 2 jobs out of 3. Elapsed 00:27:20 ------\n","  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 2, 'learning_rate': 2e-06, 'weight_decay': 0.001, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2100/2100 25:55, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.904200</td>\n","      <td>1.657105</td>\n","      <td>37.529400</td>\n","      <td>78.978000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.641200</td>\n","      <td>1.584923</td>\n","      <td>36.679700</td>\n","      <td>80.808000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [47/47 00:36]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["------ - Perplexity: 4.80 | Fitted 3 jobs out of 3. Elapsed 00:53:56 ------\n","--- Ending grid search, totalling 3 jobs. Elapsed 00:53:56 ---\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"95h0iZVF0PDq"},"source":["We evaluate the results obtained in training"]},{"cell_type":"code","metadata":{"id":"FL1TjxvpFKTE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619473779288,"user_tz":-120,"elapsed":3260679,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"ed876c8d-0ed6-4759-ce11-033ee783697c"},"source":["print('- Training results: ')\n","for model_params, score in zip(eu_models_params, eu_scores):\n","    print(f'  - Model Perplexity: {score:.2f} | Params: {model_params}')"],"execution_count":45,"outputs":[{"output_type":"stream","text":["- Training results: \n","  - Model Perplexity: 6.93 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 1, 'learning_rate': 2e-06, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n","  - Model Perplexity: 4.97 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 1, 'learning_rate': 0.0002, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n","  - Model Perplexity: 4.80 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 2, 'learning_rate': 2e-06, 'weight_decay': 0.001, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lIuGliaX0R8o"},"source":["And finally evaluate the results of the final best found model"]},{"cell_type":"code","metadata":{"id":"19ExhJ-uDjhd","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1619473851204,"user_tz":-120,"elapsed":3332591,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"ebc11214-b156-43ce-8dda-6a94ca48b0a0"},"source":["model=RobertaForMaskedLM.from_pretrained(\"../data/03_models/eu_bert_model\")\n","trainer = Trainer(\n","                    model=model,\n","                    eval_dataset=test_dataset,\n","                    data_collator=data_collator,\n","                        )\n","eval_results = trainer.evaluate()\n","print(f\" Best model perplexity on test: {math.exp(eval_results['eval_loss']):.2f}\")"],"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='618' max='618' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [618/618 01:02]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":[" Best mode perplexity: 4.80\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x4no1YBo0ctS"},"source":["### 2.2 Model training on United States COVID texts\n","The same steps are followed for the US data model as for the European model. New training parameters need to be found as the datasets differ in size.\n"]},{"cell_type":"markdown","metadata":{"id":"-jjFh3w_0ctT"},"source":["#### Dataset build"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riodkVMm0ctT","executionInfo":{"status":"ok","timestamp":1619473851601,"user_tz":-120,"elapsed":3332984,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"b56181dd-72da-4549-c2a2-c1265fa4131f"},"source":["%%time\n","from transformers import TextDataset\n","\n","dataset = TextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"../data/02_preprocessed/full_us_text.txt\",\n","    block_size=128,\n",")\n","print(len(dataset))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["15632\n","CPU times: user 149 ms, sys: 42.6 ms, total: 191 ms\n","Wall time: 194 ms\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oxw6xgb10ctV","executionInfo":{"status":"ok","timestamp":1619473851805,"user_tz":-120,"elapsed":3333185,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"5ff75c84-12a2-4ab7-9287-8822520aaa1f"},"source":["from sklearn.model_selection import train_test_split\n","train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n","print(type(train_dataset), type(test_dataset))\n","print(len(train_dataset), len(test_dataset))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["<class 'list'> <class 'list'>\n","12505 3127\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"10hULcze0ctV"},"source":["#### Data collator"]},{"cell_type":"code","metadata":{"id":"1myMCodM0ctV","executionInfo":{"status":"ok","timestamp":1619473851806,"user_tz":-120,"elapsed":3333184,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}}},"source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, #The tokenizer used for encoding the data.\n","    mlm=True, #Whether or not to use masked language modeling. The labels are -100 for non-masked tokens and the value to predict for the masked token.\n","    mlm_probability=0.15 #The probability with which to (randomly) mask tokens in the input, when mlm is set to True\n",")"],"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s5QcZ2xM0ctW"},"source":["#### Train the model using the gird search"]},{"cell_type":"markdown","metadata":{"id":"aTR_UolW0ctW"},"source":["The model is trained using the same parameters as before"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":546},"id":"5RAuCt_u0ctW","executionInfo":{"status":"ok","timestamp":1619475892660,"user_tz":-120,"elapsed":5374035,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"85e4c163-b8c2-40df-dc82-bca59dbd3e54"},"source":["us_models_params, us_scores = grid_search_for_language_modeling(\n","                    baseline_model=model,\n","                    param_grid=param_grid,\n","                    n_combinations=3,\n","                    X=train_dataset,\n","                    data_collator=data_collator,\n","                    model_name='us_bert_model',\n","                    out_dir='../data/03_models/',\n","                    tmp_dir='../data/03_models/tmp/'\n","                    )\n","\n","import pickle\n","pickle.dump(us_models_params, open('../data/03_models/us_models_params.p', 'wb'))\n","pickle.dump(us_scores, open('../data/03_models/us_scores.p', 'wb'))"],"execution_count":50,"outputs":[{"output_type":"stream","text":["- Starting grid search, totalling 3 jobs -\n","  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 1, 'learning_rate': 2e-06, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='665' max='665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [665/665 08:04, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.585100</td>\n","      <td>2.244523</td>\n","      <td>23.011900</td>\n","      <td>81.523000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [30/30 00:22]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["------ - Perplexity: 9.33 | Fitted 1 jobs out of 3. Elapsed 00:08:31 ------\n","  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 1, 'learning_rate': 0.0002, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='665' max='665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [665/665 08:06, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.749600</td>\n","      <td>1.275229</td>\n","      <td>23.991400</td>\n","      <td>78.195000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [30/30 00:23]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["------ - Perplexity: 3.56 | Fitted 2 jobs out of 3. Elapsed 00:17:05 ------\n","  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 2, 'learning_rate': 2e-06, 'weight_decay': 0.001, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1330' max='1330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1330/1330 16:27, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.633900</td>\n","      <td>1.337269</td>\n","      <td>23.798000</td>\n","      <td>78.830000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.205400</td>\n","      <td>1.261774</td>\n","      <td>23.751800</td>\n","      <td>78.984000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [30/30 00:23]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["------ - Perplexity: 3.56 | Fitted 3 jobs out of 3. Elapsed 00:34:00 ------\n","--- Ending grid search, totalling 3 jobs. Elapsed 00:34:00 ---\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-rXEihyk0ctW"},"source":["We evaluate the results obtained in training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NC8tQzc00ctW","executionInfo":{"status":"ok","timestamp":1619475892853,"user_tz":-120,"elapsed":5374224,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"a65da69f-4f34-4cb6-a060-1df01a791076"},"source":["print('- Training results: ')\n","for model_params, score in zip(us_models_params, us_scores):\n","    print(f'  - Model Perplexity: {score:.2f} | Params: {model_params}')"],"execution_count":51,"outputs":[{"output_type":"stream","text":["- Training results: \n","  - Model Perplexity: 9.33 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 1, 'learning_rate': 2e-06, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n","  - Model Perplexity: 3.56 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 1, 'learning_rate': 0.0002, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n","  - Model Perplexity: 3.56 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'evaluation_strategy': 'epoch', 'num_train_epochs': 2, 'learning_rate': 2e-06, 'weight_decay': 0.001, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 64, 'save_steps': 10000, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q2HmOlWL0ctX"},"source":["And finally evaluate the results of the final best found model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"id":"0VpvwX2p0ctX","executionInfo":{"status":"ok","timestamp":1619475943664,"user_tz":-120,"elapsed":5425030,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"c3d9e8e7-656f-439b-e8d8-703556ed11d2"},"source":["model=RobertaForMaskedLM.from_pretrained(\"../data/03_models/us_bert_model\")\n","trainer = Trainer(\n","                    model=model,\n","                    eval_dataset=test_dataset,\n","                    data_collator=data_collator,\n","                        )\n","eval_results = trainer.evaluate()\n","print(f\" Best model perplexity on test: {math.exp(eval_results['eval_loss']):.2f}\")"],"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [391/391 00:42]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":[" Best mode perplexity: 3.60\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d0caceCy_p1-"},"source":["## 3. Compare the model results"]},{"cell_type":"markdown","metadata":{"id":"iIQJ8ND_AEhl"},"source":["Aside from looking at the training and eval losses going down, the easiest way to check whether our language model is learning anything interesting is via the `FillMaskPipeline`.\n","\n","Pipelines are simple wrappers around tokenizers and models, and the 'fill-mask' one will let you input a sequence containing a masked token (here, transformers.pipeline.tokenizer.mask_token) and return a list of the most probable filled sequences, with their probabilities.\n","\n","The predictions are compared to the predictions outputed from the base model that was used to fine tune this model."]},{"cell_type":"code","metadata":{"id":"ltXgXyCbAJLY","executionInfo":{"status":"ok","timestamp":1619475967900,"user_tz":-120,"elapsed":5449265,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}}},"source":["from transformers import pipeline, RobertaForMaskedLM\n","model=RobertaForMaskedLM.from_pretrained(\"../data/03_models/eu_bert_model\")\n","eu_model_pipeline = pipeline(\n","    \"fill-mask\",\n","    model=model,\n","    tokenizer=model_checkpoint\n",")\n","\n","model=RobertaForMaskedLM.from_pretrained(\"../data/03_models/us_bert_model\")\n","us_model_pipeline = pipeline(\n","    \"fill-mask\",\n","    model=model,\n","    tokenizer=model_checkpoint\n",")\n","\n","model = RobertaForMaskedLM.from_pretrained(model_checkpoint)\n","old_model_pipeline = pipeline(\n","    \"fill-mask\",\n","    model=model,\n","    tokenizer=model_checkpoint\n",")"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"roVhxqJA8VxF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619476097527,"user_tz":-120,"elapsed":1098,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"a8d0c081-bb96-4950-9c62-76eeee3ac5e5"},"source":["sequence = f\"Coronavirus is a very bad <mask>\"\n","eu_model_pipeline_results = eu_model_pipeline(sequence)\n","us_model_pipeline_results = us_model_pipeline(sequence)\n","old_model_pipeline_results = old_model_pipeline(sequence)\n","\n","for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n","    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n","    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n","    print(f'OLD MODEL {idx} token is            {old_prediction}')\n","    print('--------------------------------')"],"execution_count":61,"outputs":[{"output_type":"stream","text":["EUROPEAN MODEL 0 token is       {'sequence': 'Coronavirus is a very bad virus', 'score': 0.2691511809825897, 'token': 6793, 'token_str': ' virus'}\n","UNITED STATES MODEL 0 token is  {'sequence': 'Coronavirus is a very bad disease', 'score': 0.25462937355041504, 'token': 2199, 'token_str': ' disease'}\n","OLD MODEL 0 token is            {'sequence': 'Coronavirus is a very bad virus', 'score': 0.7009516954421997, 'token': 6793, 'token_str': ' virus'}\n","--------------------------------\n","EUROPEAN MODEL 1 token is       {'sequence': 'Coronavirus is a very bad case', 'score': 0.16394412517547607, 'token': 403, 'token_str': ' case'}\n","UNITED STATES MODEL 1 token is  {'sequence': 'Coronavirus is a very bad virus', 'score': 0.12848496437072754, 'token': 6793, 'token_str': ' virus'}\n","OLD MODEL 1 token is            {'sequence': 'Coronavirus is a very bad thing', 'score': 0.1592380851507187, 'token': 631, 'token_str': ' thing'}\n","--------------------------------\n","EUROPEAN MODEL 2 token is       {'sequence': 'Coronavirus is a very bad disease', 'score': 0.11183398216962814, 'token': 2199, 'token_str': ' disease'}\n","UNITED STATES MODEL 2 token is  {'sequence': 'Coronavirus is a very bad strain', 'score': 0.11882656067609787, 'token': 8793, 'token_str': ' strain'}\n","OLD MODEL 2 token is            {'sequence': 'Coronavirus is a very bad guy', 'score': 0.023437274619936943, 'token': 2173, 'token_str': ' guy'}\n","--------------------------------\n","EUROPEAN MODEL 3 token is       {'sequence': 'Coronavirus is a very bad problem', 'score': 0.054155610501766205, 'token': 936, 'token_str': ' problem'}\n","UNITED STATES MODEL 3 token is  {'sequence': 'Coronavirus is a very bad case', 'score': 0.10975583642721176, 'token': 403, 'token_str': ' case'}\n","OLD MODEL 3 token is            {'sequence': 'Coronavirus is a very bad disease', 'score': 0.0223777424544096, 'token': 2199, 'token_str': ' disease'}\n","--------------------------------\n","EUROPEAN MODEL 4 token is       {'sequence': 'Coronavirus is a very bad candidate', 'score': 0.030156884342432022, 'token': 1984, 'token_str': ' candidate'}\n","UNITED STATES MODEL 4 token is  {'sequence': 'Coronavirus is a very bad sleeper', 'score': 0.08060867339372635, 'token': 36170, 'token_str': ' sleeper'}\n","OLD MODEL 4 token is            {'sequence': 'Coronavirus is a very bad idea', 'score': 0.008799838833510876, 'token': 1114, 'token_str': ' idea'}\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m39wmHjv8VxE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619476098107,"user_tz":-120,"elapsed":1671,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"a31218f6-8973-4ffa-c8cd-4a96e4d4215f"},"source":["sequence = f\"Coronavirus is a very <mask> disease\"\n","eu_model_pipeline_results = eu_model_pipeline(sequence)\n","us_model_pipeline_results = us_model_pipeline(sequence)\n","old_model_pipeline_results = old_model_pipeline(sequence)\n","\n","for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n","    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n","    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n","    print(f'OLD MODEL {idx} token is            {old_prediction}')\n","    print('--------------------------------')"],"execution_count":62,"outputs":[{"output_type":"stream","text":["EUROPEAN MODEL 0 token is       {'sequence': 'Coronavirus is a very rare disease', 'score': 0.24148690700531006, 'token': 3159, 'token_str': ' rare'}\n","UNITED STATES MODEL 0 token is  {'sequence': 'Coronavirus is a very rare disease', 'score': 0.28560319542884827, 'token': 3159, 'token_str': ' rare'}\n","OLD MODEL 0 token is            {'sequence': 'Coronavirus is a very rare disease', 'score': 0.19685015082359314, 'token': 3159, 'token_str': ' rare'}\n","--------------------------------\n","EUROPEAN MODEL 1 token is       {'sequence': 'Coronavirus is a very serious disease', 'score': 0.21718955039978027, 'token': 1473, 'token_str': ' serious'}\n","UNITED STATES MODEL 1 token is  {'sequence': 'Coronavirus is a very infectious disease', 'score': 0.08091650158166885, 'token': 19166, 'token_str': ' infectious'}\n","OLD MODEL 1 token is            {'sequence': 'Coronavirus is a very contagious disease', 'score': 0.17108966410160065, 'token': 27432, 'token_str': ' contagious'}\n","--------------------------------\n","EUROPEAN MODEL 2 token is       {'sequence': 'Coronavirus is a very common disease', 'score': 0.10462453216314316, 'token': 1537, 'token_str': ' common'}\n","UNITED STATES MODEL 2 token is  {'sequence': 'Coronavirus is a very serious disease', 'score': 0.06539969146251678, 'token': 1473, 'token_str': ' serious'}\n","OLD MODEL 2 token is            {'sequence': 'Coronavirus is a very serious disease', 'score': 0.12323196977376938, 'token': 1473, 'token_str': ' serious'}\n","--------------------------------\n","EUROPEAN MODEL 3 token is       {'sequence': 'Coronavirus is a very dangerous disease', 'score': 0.06394099444150925, 'token': 2702, 'token_str': ' dangerous'}\n","UNITED STATES MODEL 3 token is  {'sequence': 'Coronavirus is a very large disease', 'score': 0.03953428938984871, 'token': 739, 'token_str': ' large'}\n","OLD MODEL 3 token is            {'sequence': 'Coronavirus is a very common disease', 'score': 0.07545918971300125, 'token': 1537, 'token_str': ' common'}\n","--------------------------------\n","EUROPEAN MODEL 4 token is       {'sequence': 'Coronavirus is a very severe disease', 'score': 0.05758557468652725, 'token': 3814, 'token_str': ' severe'}\n","UNITED STATES MODEL 4 token is  {'sequence': 'Coronavirus is a very unusual disease', 'score': 0.031309824436903, 'token': 5425, 'token_str': ' unusual'}\n","OLD MODEL 4 token is            {'sequence': 'Coronavirus is a very nasty disease', 'score': 0.061881065368652344, 'token': 15455, 'token_str': ' nasty'}\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A9F1Gpfb8VxF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619476098678,"user_tz":-120,"elapsed":2238,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"575bc057-7e14-4631-e3b1-62ded4553991"},"source":["sequence = f\"Covid is a very bad <mask>\"\n","eu_model_pipeline_results = eu_model_pipeline(sequence)\n","us_model_pipeline_results = us_model_pipeline(sequence)\n","old_model_pipeline_results = old_model_pipeline(sequence)\n","\n","for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n","    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n","    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n","    print(f'OLD MODEL {idx} token is            {old_prediction}')\n","    print('--------------------------------')"],"execution_count":63,"outputs":[{"output_type":"stream","text":["EUROPEAN MODEL 0 token is       {'sequence': 'Covid is a very bad disease', 'score': 0.2005854845046997, 'token': 2199, 'token_str': ' disease'}\n","UNITED STATES MODEL 0 token is  {'sequence': 'Covid is a very bad virus', 'score': 0.35650452971458435, 'token': 6793, 'token_str': ' virus'}\n","OLD MODEL 0 token is            {'sequence': 'Covid is a very bad guy', 'score': 0.0871887058019638, 'token': 2173, 'token_str': ' guy'}\n","--------------------------------\n","EUROPEAN MODEL 1 token is       {'sequence': 'Covid is a very bad virus', 'score': 0.15339580178260803, 'token': 6793, 'token_str': ' virus'}\n","UNITED STATES MODEL 1 token is  {'sequence': 'Covid is a very bad disease', 'score': 0.10436339676380157, 'token': 2199, 'token_str': ' disease'}\n","OLD MODEL 1 token is            {'sequence': 'Covid is a very bad dog', 'score': 0.05724494904279709, 'token': 2335, 'token_str': ' dog'}\n","--------------------------------\n","EUROPEAN MODEL 2 token is       {'sequence': 'Covid is a very bad drug', 'score': 0.11124885827302933, 'token': 1262, 'token_str': ' drug'}\n","UNITED STATES MODEL 2 token is  {'sequence': 'Covid is a very bad sleeper', 'score': 0.08871738612651825, 'token': 36170, 'token_str': ' sleeper'}\n","OLD MODEL 2 token is            {'sequence': 'Covid is a very bad cat', 'score': 0.05441278964281082, 'token': 4758, 'token_str': ' cat'}\n","--------------------------------\n","EUROPEAN MODEL 3 token is       {'sequence': 'Covid is a very bad case', 'score': 0.06523500382900238, 'token': 403, 'token_str': ' case'}\n","UNITED STATES MODEL 3 token is  {'sequence': 'Covid is a very bad strain', 'score': 0.07012195140123367, 'token': 8793, 'token_str': ' strain'}\n","OLD MODEL 3 token is            {'sequence': 'Covid is a very bad idea', 'score': 0.043847549706697464, 'token': 1114, 'token_str': ' idea'}\n","--------------------------------\n","EUROPEAN MODEL 4 token is       {'sequence': 'Covid is a very bad problem', 'score': 0.04499393329024315, 'token': 936, 'token_str': ' problem'}\n","UNITED STATES MODEL 4 token is  {'sequence': 'Covid is a very bad case', 'score': 0.046806320548057556, 'token': 403, 'token_str': ' case'}\n","OLD MODEL 4 token is            {'sequence': 'Covid is a very bad person', 'score': 0.04053870216012001, 'token': 621, 'token_str': ' person'}\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OijIQdA68VxF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619476099193,"user_tz":-120,"elapsed":2749,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"a03619aa-cf9a-416d-8060-0ce25ef2e995"},"source":["sequence = f\"Covid is a very <mask> disease\"\n","eu_model_pipeline_results = eu_model_pipeline(sequence)\n","us_model_pipeline_results = us_model_pipeline(sequence)\n","old_model_pipeline_results = old_model_pipeline(sequence)\n","\n","for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n","    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n","    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n","    print(f'OLD MODEL {idx} token is            {old_prediction}')\n","    print('--------------------------------')"],"execution_count":64,"outputs":[{"output_type":"stream","text":["EUROPEAN MODEL 0 token is       {'sequence': 'Covid is a very serious disease', 'score': 0.18287736177444458, 'token': 1473, 'token_str': ' serious'}\n","UNITED STATES MODEL 0 token is  {'sequence': 'Covid is a very rare disease', 'score': 0.2775634825229645, 'token': 3159, 'token_str': ' rare'}\n","OLD MODEL 0 token is            {'sequence': 'Covid is a very rare disease', 'score': 0.3451760709285736, 'token': 3159, 'token_str': ' rare'}\n","--------------------------------\n","EUROPEAN MODEL 1 token is       {'sequence': 'Covid is a very dangerous disease', 'score': 0.17433346807956696, 'token': 2702, 'token_str': ' dangerous'}\n","UNITED STATES MODEL 1 token is  {'sequence': 'Covid is a very infectious disease', 'score': 0.15055875480175018, 'token': 19166, 'token_str': ' infectious'}\n","OLD MODEL 1 token is            {'sequence': 'Covid is a very serious disease', 'score': 0.10931653529405594, 'token': 1473, 'token_str': ' serious'}\n","--------------------------------\n","EUROPEAN MODEL 2 token is       {'sequence': 'Covid is a very rare disease', 'score': 0.12103328108787537, 'token': 3159, 'token_str': ' rare'}\n","UNITED STATES MODEL 2 token is  {'sequence': 'Covid is a very large disease', 'score': 0.04119279235601425, 'token': 739, 'token_str': ' large'}\n","OLD MODEL 2 token is            {'sequence': 'Covid is a very common disease', 'score': 0.07898864150047302, 'token': 1537, 'token_str': ' common'}\n","--------------------------------\n","EUROPEAN MODEL 3 token is       {'sequence': 'Covid is a very common disease', 'score': 0.09799124300479889, 'token': 1537, 'token_str': ' common'}\n","UNITED STATES MODEL 3 token is  {'sequence': 'Covid is a very advanced disease', 'score': 0.039472926408052444, 'token': 3319, 'token_str': ' advanced'}\n","OLD MODEL 3 token is            {'sequence': 'Covid is a very dangerous disease', 'score': 0.04305536672472954, 'token': 2702, 'token_str': ' dangerous'}\n","--------------------------------\n","EUROPEAN MODEL 4 token is       {'sequence': 'Covid is a very aggressive disease', 'score': 0.06558293104171753, 'token': 4353, 'token_str': ' aggressive'}\n","UNITED STATES MODEL 4 token is  {'sequence': 'Covid is a very emerging disease', 'score': 0.03342151269316673, 'token': 3947, 'token_str': ' emerging'}\n","OLD MODEL 4 token is            {'sequence': 'Covid is a very aggressive disease', 'score': 0.03993546962738037, 'token': 4353, 'token_str': ' aggressive'}\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pfs7SI7E9Ei3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619476099517,"user_tz":-120,"elapsed":3070,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"31d6a3ed-2a62-47a6-e316-f9150d68323c"},"source":["sequence = f\"<mask> is a disease\"\n","eu_model_pipeline_results = eu_model_pipeline(sequence)\n","us_model_pipeline_results = us_model_pipeline(sequence)\n","old_model_pipeline_results = old_model_pipeline(sequence)\n","\n","for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n","    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n","    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n","    print(f'OLD MODEL {idx} token is            {old_prediction}')\n","    print('--------------------------------')"],"execution_count":65,"outputs":[{"output_type":"stream","text":["EUROPEAN MODEL 0 token is       {'sequence': ' it is a disease', 'score': 0.14300011098384857, 'token': 24, 'token_str': ' it'}\n","UNITED STATES MODEL 0 token is  {'sequence': ' there is a disease', 'score': 0.36707645654678345, 'token': 89, 'token_str': ' there'}\n","OLD MODEL 0 token is            {'sequence': 'Life is a disease', 'score': 0.18752367794513702, 'token': 12116, 'token_str': 'Life'}\n","--------------------------------\n","EUROPEAN MODEL 1 token is       {'sequence': ' this is a disease', 'score': 0.0931367352604866, 'token': 42, 'token_str': ' this'}\n","UNITED STATES MODEL 1 token is  {'sequence': '  is a disease', 'score': 0.28947973251342773, 'token': 1437, 'token_str': ' '}\n","OLD MODEL 1 token is            {'sequence': 'It is a disease', 'score': 0.0876104012131691, 'token': 243, 'token_str': 'It'}\n","--------------------------------\n","EUROPEAN MODEL 2 token is       {'sequence': ' disease is a disease', 'score': 0.08356322348117828, 'token': 2199, 'token_str': ' disease'}\n","UNITED STATES MODEL 2 token is  {'sequence': ' that is a disease', 'score': 0.049283478409051895, 'token': 14, 'token_str': ' that'}\n","OLD MODEL 2 token is            {'sequence': 'Language is a disease', 'score': 0.07092619687318802, 'token': 46969, 'token_str': 'Language'}\n","--------------------------------\n","EUROPEAN MODEL 3 token is       {'sequence': ' cancer is a disease', 'score': 0.04427402839064598, 'token': 1668, 'token_str': ' cancer'}\n","UNITED STATES MODEL 3 token is  {'sequence': 'there is a disease', 'score': 0.0155683858320117, 'token': 8585, 'token_str': 'there'}\n","OLD MODEL 3 token is            {'sequence': 'Death is a disease', 'score': 0.05379626527428627, 'token': 34811, 'token_str': 'Death'}\n","--------------------------------\n","EUROPEAN MODEL 4 token is       {'sequence': ' infection is a disease', 'score': 0.03693173825740814, 'token': 7910, 'token_str': ' infection'}\n","UNITED STATES MODEL 4 token is  {'sequence': ' this is a disease', 'score': 0.01325808186084032, 'token': 42, 'token_str': ' this'}\n","OLD MODEL 4 token is            {'sequence': 'Love is a disease', 'score': 0.05184708535671234, 'token': 16587, 'token_str': 'Love'}\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qbXoYXCd9JVT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619476100234,"user_tz":-120,"elapsed":3783,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"c811dad7-96f5-41f7-9231-cc8e7aa9b6c0"},"source":["sequence = f\"The <mask> of the coronavirus pandemic are very serious\"\n","eu_model_pipeline_results = eu_model_pipeline(sequence)\n","us_model_pipeline_results = us_model_pipeline(sequence)\n","old_model_pipeline_results = old_model_pipeline(sequence)\n","\n","for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n","    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n","    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n","    print(f'OLD MODEL {idx} token is            {old_prediction}')\n","    print('--------------------------------')"],"execution_count":66,"outputs":[{"output_type":"stream","text":["EUROPEAN MODEL 0 token is       {'sequence': 'The consequences of the coronavirus pandemic are very serious', 'score': 0.7281331419944763, 'token': 4914, 'token_str': ' consequences'}\n","UNITED STATES MODEL 0 token is  {'sequence': 'The consequences of the coronavirus pandemic are very serious', 'score': 0.5790644288063049, 'token': 4914, 'token_str': ' consequences'}\n","OLD MODEL 0 token is            {'sequence': 'The consequences of the coronavirus pandemic are very serious', 'score': 0.6111682057380676, 'token': 4914, 'token_str': ' consequences'}\n","--------------------------------\n","EUROPEAN MODEL 1 token is       {'sequence': 'The effects of the coronavirus pandemic are very serious', 'score': 0.1942291110754013, 'token': 3038, 'token_str': ' effects'}\n","UNITED STATES MODEL 1 token is  {'sequence': 'The effects of the coronavirus pandemic are very serious', 'score': 0.3185788691043854, 'token': 3038, 'token_str': ' effects'}\n","OLD MODEL 1 token is            {'sequence': 'The implications of the coronavirus pandemic are very serious', 'score': 0.15928715467453003, 'token': 8819, 'token_str': ' implications'}\n","--------------------------------\n","EUROPEAN MODEL 2 token is       {'sequence': 'The repercussions of the coronavirus pandemic are very serious', 'score': 0.028144286945462227, 'token': 24147, 'token_str': ' repercussions'}\n","UNITED STATES MODEL 2 token is  {'sequence': 'The impacts of the coronavirus pandemic are very serious', 'score': 0.03710600733757019, 'token': 7342, 'token_str': ' impacts'}\n","OLD MODEL 2 token is            {'sequence': 'The effects of the coronavirus pandemic are very serious', 'score': 0.08231475949287415, 'token': 3038, 'token_str': ' effects'}\n","--------------------------------\n","EUROPEAN MODEL 3 token is       {'sequence': 'The implications of the coronavirus pandemic are very serious', 'score': 0.017802832648158073, 'token': 8819, 'token_str': ' implications'}\n","UNITED STATES MODEL 3 token is  {'sequence': 'The implications of the coronavirus pandemic are very serious', 'score': 0.013127830810844898, 'token': 8819, 'token_str': ' implications'}\n","OLD MODEL 3 token is            {'sequence': 'The risks of the coronavirus pandemic are very serious', 'score': 0.02252395823597908, 'token': 2476, 'token_str': ' risks'}\n","--------------------------------\n","EUROPEAN MODEL 4 token is       {'sequence': 'The impacts of the coronavirus pandemic are very serious', 'score': 0.015036161988973618, 'token': 7342, 'token_str': ' impacts'}\n","UNITED STATES MODEL 4 token is  {'sequence': 'The circumstances of the coronavirus pandemic are very serious', 'score': 0.006700341589748859, 'token': 4215, 'token_str': ' circumstances'}\n","OLD MODEL 4 token is            {'sequence': 'The repercussions of the coronavirus pandemic are very serious', 'score': 0.018072325736284256, 'token': 24147, 'token_str': ' repercussions'}\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sZujADpu9S_z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619476100885,"user_tz":-120,"elapsed":4430,"user":{"displayName":"Daniel Díez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64","userId":"04428453110580774456"}},"outputId":"1c896a8d-590f-4e02-d2b2-a9987e41db8b"},"source":["sequence = f\"The consequences of the <mask> are very serious\"\n","eu_model_pipeline_results = eu_model_pipeline(sequence)\n","us_model_pipeline_results = us_model_pipeline(sequence)\n","old_model_pipeline_results = old_model_pipeline(sequence)\n","\n","for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n","    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n","    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n","    print(f'OLD MODEL {idx} token is            {old_prediction}')\n","    print('--------------------------------')"],"execution_count":67,"outputs":[{"output_type":"stream","text":["EUROPEAN MODEL 0 token is       {'sequence': 'The consequences of the crisis are very serious', 'score': 0.6593908071517944, 'token': 1486, 'token_str': ' crisis'}\n","UNITED STATES MODEL 0 token is  {'sequence': 'The consequences of the disaster are very serious', 'score': 0.3059934079647064, 'token': 4463, 'token_str': ' disaster'}\n","OLD MODEL 0 token is            {'sequence': 'The consequences of the attack are very serious', 'score': 0.07320790737867355, 'token': 908, 'token_str': ' attack'}\n","--------------------------------\n","EUROPEAN MODEL 1 token is       {'sequence': 'The consequences of the measures are very serious', 'score': 0.0319034680724144, 'token': 1797, 'token_str': ' measures'}\n","UNITED STATES MODEL 1 token is  {'sequence': 'The consequences of the act are very serious', 'score': 0.09415481239557266, 'token': 1760, 'token_str': ' act'}\n","OLD MODEL 1 token is            {'sequence': 'The consequences of the decision are very serious', 'score': 0.04880741238594055, 'token': 568, 'token_str': ' decision'}\n","--------------------------------\n","EUROPEAN MODEL 2 token is       {'sequence': 'The consequences of the emergency are very serious', 'score': 0.027222851291298866, 'token': 1923, 'token_str': ' emergency'}\n","UNITED STATES MODEL 2 token is  {'sequence': 'The consequences of the crisis are very serious', 'score': 0.07706554234027863, 'token': 1486, 'token_str': ' crisis'}\n","OLD MODEL 2 token is            {'sequence': 'The consequences of the ban are very serious', 'score': 0.037303466349840164, 'token': 2020, 'token_str': ' ban'}\n","--------------------------------\n","EUROPEAN MODEL 3 token is       {'sequence': 'The consequences of the outbreak are very serious', 'score': 0.02617623843252659, 'token': 8507, 'token_str': ' outbreak'}\n","UNITED STATES MODEL 3 token is  {'sequence': 'The consequences of the emergency are very serious', 'score': 0.034987207502126694, 'token': 1923, 'token_str': ' emergency'}\n","OLD MODEL 3 token is            {'sequence': 'The consequences of the accident are very serious', 'score': 0.028222709894180298, 'token': 3213, 'token_str': ' accident'}\n","--------------------------------\n","EUROPEAN MODEL 4 token is       {'sequence': 'The consequences of the event are very serious', 'score': 0.020836584270000458, 'token': 515, 'token_str': ' event'}\n","UNITED STATES MODEL 4 token is  {'sequence': 'The consequences of the outbreak are very serious', 'score': 0.028686225414276123, 'token': 8507, 'token_str': ' outbreak'}\n","OLD MODEL 4 token is            {'sequence': 'The consequences of the incident are very serious', 'score': 0.028121178969740868, 'token': 1160, 'token_str': ' incident'}\n","--------------------------------\n"],"name":"stdout"}]}]}
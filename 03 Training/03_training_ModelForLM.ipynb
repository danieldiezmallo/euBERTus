{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13604,
     "status": "ok",
     "timestamp": 1619470532162,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "5duRggBRZKvP",
    "outputId": "9ee5099c-2223-43ca-babe-f925d5ae77e0"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drivedrive.mount('/content/drive')\n",
    "#%cd /content/drive/MyDrive/tfm_code/03 Training\n",
    "#%pwd\n",
    "# Install `transformers` from master\n",
    "#!pip install transformers==4.5.1\n",
    "# !pip install git+https://github.com/huggingface/transformers\n",
    "#!pip install torch\n",
    "#!pip install sklearn\n",
    "# transformers version at notebook update --- 2.11.0\n",
    "# tokenizers version at notebook update --- 0.8.0rc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQpUC_CDhnWW"
   },
   "source": [
    "## 1. Load the base models and the tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13936,
     "status": "ok",
     "timestamp": 1619470532500,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "kD140sFjh0LQ",
    "outputId": "785d1809-40de-4ef2-9a3a-2a38ae714754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  3 21:32:09 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla M60           Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   31C    P0    38W / 150W |      0MiB /  7618MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check that we have a GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13932,
     "status": "ok",
     "timestamp": 1619470532501,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "VNZZs-r6iKAV",
    "outputId": "3b6cfb6c-5565-49e8-ee2b-c9ec4dbf10e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that PyTorch sees it\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dR8Jv1Dy1ya"
   },
   "source": [
    "### Model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 13933,
     "status": "ok",
     "timestamp": 1619470532503,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "3WJP178yy0yh"
   },
   "outputs": [],
   "source": [
    "# Select the model baseline to perform the transfer learning from\n",
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "new_tokens = ['covid', 'covid-19', 'coronavirus', 'sars', 'sars-cov-2', 'pandemic', 'outbreak']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAwQ82JiE5pi"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 14123,
     "status": "ok",
     "timestamp": 1619470532699,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "4keFBUjQFOD1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/03_models/tokenizer/tokenizer_config.json',\n",
       " '../data/03_models/tokenizer/special_tokens_map.json',\n",
       " '../data/03_models/tokenizer/vocab.txt',\n",
       " '../data/03_models/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "tokenizer.save_pretrained('../data/03_models/tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yNCw-3hFv9h"
   },
   "source": [
    "### Model\n",
    "Finally let's initialize our model. We are looking to train from a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 22840,
     "status": "ok",
     "timestamp": 1619470541422,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "BzMqR-dzF4Ro"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30528, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model.resize_token_embeddings(len(tokenizer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22841,
     "status": "ok",
     "timestamp": 1619470541429,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "jU6JhBSTKiaM",
    "outputId": "ab6c983c-e6c5-41e7-e439-b5da1da4edda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66990144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri2BIQKqjfHm"
   },
   "source": [
    "## 2. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mNFxHtLzylq"
   },
   "source": [
    "### 2.1 Define a grid search function for the training\n",
    "\n",
    "Finally, in order to perform the training, a grid search function that allows random search is created. The functions does the following steps:\n",
    "* It finds all possible combinations of parameters among the parameters grid\n",
    "* Then, if a maximum number of fits is provided, it selects n_combinations random parameter combinations from the total list\n",
    "* It creates a directory to store the temporary trained models so they don't have to be loaded in memory\n",
    "* It splits the data into train and validations sets\n",
    "* Then, for every parameter combination in the list:\n",
    "    * It creates a transformers.Trainer object with a transfomers.TrainingArguments, that is created from the parameter combination dictionary, the baseline model, the datacollator to created the training batches by masking random tokens in the training set\n",
    "    * It trains the model\n",
    "    * It evaluates the perplexity of the model on the validation set\n",
    "    * It saves the score and the parameters used in a list\n",
    "    * It writes the model to disk\n",
    "* After all the models are trained, it finds the one with the lowest perplexity\n",
    "* It moves the model to the output folder\n",
    "* Finally, it returns all the models and perplexitys cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 22844,
     "status": "ok",
     "timestamp": 1619470541432,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "3aNSMwex45B8"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import time\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import os\n",
    "from random import sample\n",
    "from shutil import rmtree, move\n",
    "def grid_search_for_language_modeling(baseline_model=None, param_grid={}, n_combinations=None, X=None, data_collator=None, validation_size=0.15, random_state=42, model_name='model', out_dir='models/', tmp_dir='grid_search/'): \n",
    "    \"\"\"\n",
    "    Performs grid search over a grid of parameters for an ML model and another grid of parameters for a function applied to training data in order to augment it\n",
    "    It uses a custom cross validation function that only applies the function to the training data and validates on clean data\n",
    "    -------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "        - model: scikit-learn like model\n",
    "        - model_grid: dictionary of parameters to perform gird search on the _model\n",
    "        - X (dataframe): train data (np.array)\n",
    "        - validation_size\n",
    "\n",
    "    Returns:\n",
    "        - best_model: a dictionaty that contains the results with the best model found by performing the grid search over the _model and _function\n",
    "            + _best_model'\n",
    "            + _best_model_params\n",
    "            + _best_function_params\n",
    "            + _best_score\n",
    "    \"\"\"\n",
    "    # Get all combinations of parameters in grid\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations_list = [dict(zip(keys, v)) for v in product(*values)]\n",
    "    \n",
    "    for param_combination in param_combinations_list:\n",
    "        param_combination['eval_steps'] = (len(train_dataset) // param_combination[\"per_device_train_batch_size\"]) + 1\n",
    "\n",
    "    # If a max number of combinations is provided then n_combinations random param combinations are selected from the list\n",
    "    if n_combinations:\n",
    "        param_combinations_list = sample(param_combinations_list, n_combinations)\n",
    "    total_fits = len(param_combinations_list)\n",
    "    model_params, scores = [], []\n",
    "\n",
    "    # Create directory to save temporary models\n",
    "    if os.path.isdir(tmp_dir):\n",
    "        rmtree(tmp_dir)\n",
    "    os.makedirs(tmp_dir)\n",
    "\n",
    "    # Divide the dataset for validation\n",
    "    X_train, X_test = train_test_split(X, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    # Start grid search\n",
    "    start = time.time() # Get initial time of training\n",
    "    print(f'- Starting grid search, totalling {total_fits} jobs -')\n",
    "    for param_combination in param_combinations_list:\n",
    "\n",
    "        # Instantiate a model with the given param combination in the iteration\n",
    "        print(f'  - Training model {param_combination}')\n",
    "        training_args = TrainingArguments(**param_combination) # Unpacking the param grid\n",
    "        trainer = Trainer(\n",
    "                            model=baseline_model,\n",
    "                            args=training_args,\n",
    "                            train_dataset=X_train,\n",
    "                            eval_dataset=X_test,\n",
    "                            data_collator=data_collator,\n",
    "                        )\n",
    "        # Train the model\n",
    "        trainer.train()\n",
    "\n",
    "        # Save the model\n",
    "        trainer.save_model(f'{tmp_dir}/{len(os.listdir(tmp_dir))}')\n",
    "\n",
    "        # Evaluate performance\n",
    "        eval_results = trainer.evaluate()\n",
    "        model_score = math.exp(eval_results['eval_loss'])\n",
    "\n",
    "        model_params.append(param_combination)\n",
    "        scores.append(model_score)\n",
    "\n",
    "        elapsed_time = time.time() - start\n",
    "        print(f'------ - Perplexity: {model_score:.2f} | Fitted {len(scores)} jobs out of {total_fits}. Elapsed {time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))} ------') \n",
    "            \n",
    "    elapsed_time = time.time() - start\n",
    "    print('--- Ending grid search, totalling {} jobs. Elapsed {} ---'.format(total_fits, time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))) \n",
    "    \n",
    "    # Get index og the model with the best score\n",
    "    best_index = scores.index(min(scores))\n",
    "    \n",
    "    # Move model to output_dir\n",
    "    os.rename(f'{tmp_dir}/{best_index}', f'{tmp_dir}/{model_name}')\n",
    "\n",
    "    # Remove the model in the output dir\n",
    "    if os.path.isdir(f'{out_dir}/{model_name}'):\n",
    "        rmtree(f'{out_dir}/{model_name}')\n",
    "    \n",
    "    # Move the contents of the new best model to the output dir\n",
    "    move(f'{tmp_dir}/{model_name}', f'{out_dir}/{model_name}')\n",
    "    # Remove working dir\n",
    "    rmtree(tmp_dir)\n",
    "\n",
    "    # Return the best params and score in a dict\n",
    "    return model_params, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBtUHRMliOLM"
   },
   "source": [
    "### 2.2 Model training on European COVID texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rY5hwSn4zsOy"
   },
   "source": [
    "#### Dataset build\n",
    "\n",
    "We'll build our dataset by applying our tokenizer to our text file.\n",
    "\n",
    "TextDataset: reads the full input text, tokenizes it and cuts it in block_sized chunks. Then adds special tokens (here just <s> or [\"SEP\"]/[\"CLS\"])\n",
    "\n",
    "LineByLineTextDataset: reads each line separately, tokenizes and truncates the lines to block_size. Adds special tokens.\n",
    "\n",
    "use TextDataset because --line-by-line will throw away a lot of data if not used correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23204,
     "status": "ok",
     "timestamp": 1619470541796,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "GlvP_A-THEEl",
    "outputId": "e0fe0c87-ad71-46c0-b42b-1b5b0d476e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24477\n",
      "CPU times: user 160 ms, sys: 48.1 ms, total: 208 ms\n",
      "Wall time: 206 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import TextDataset\n",
    "\n",
    "dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"../data/02_preprocessed/full_eu_text.txt\",\n",
    "    block_size=128,\n",
    ")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23414,
     "status": "ok",
     "timestamp": 1619470542011,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "raCoMBu2kZ4h",
    "outputId": "58158388-8ff4-4419-c241-35cb57b362b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n",
      "19581 4896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "print(type(train_dataset), type(test_dataset))\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDLs73HcIHk5"
   },
   "source": [
    "#### Data collator\n",
    "[Data collators](https://huggingface.co/transformers/master/main_classes/data_collator.html) are objects that will form a batch by using a list of dataset elements as input. These elements are of the same type as the elements of train_dataset or eval_dataset. This is just a small helper that will help us batch different samples of the dataset together into an object that PyTorch knows how to perform backprop on.\n",
    "\n",
    "[DataCollatorForLanguageModeling](https://huggingface.co/transformers/master/main_classes/data_collator.html#datacollatorforlanguagemodeling): Data collator used for language modeling. Inputs are dynamically padded to the maximum length of a batch if they are not all of the same length.\n",
    "\n",
    "For best performance, this data collator should be used with a dataset having items that are dictionaries or BatchEncoding, with the \"special_tokens_mask\" key, as returned by a PreTrainedTokenizer or a PreTrainedTokenizerFast with the argument return_special_tokens_mask=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 23415,
     "status": "ok",
     "timestamp": 1619470542012,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "zTgWPa9Dipk2"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, #The tokenizer used for encoding the data.\n",
    "    mlm=True, #Whether or not to use masked language modeling. The labels are -100 for non-masked tokens and the value to predict for the masked token.\n",
    "    mlm_probability=0.15 #The probability with which to (randomly) mask tokens in the input, when mlm is set to True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvmDL5tFzaz6"
   },
   "source": [
    "#### Train the model using the gird search\n",
    "First the parameters to perform the search over the training are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 23634,
     "status": "ok",
     "timestamp": 1619470542233,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "JVBm-tO1x6Eu"
   },
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "            output_dir=[\"../data/03_models/trainer/\"],\n",
    "            overwrite_output_dir=[True],\n",
    "            num_train_epochs=[3],\n",
    "            learning_rate=[2e-5, 3e-5, 5e-5],\n",
    "            weight_decay=[0.01, 0.005],\n",
    "            per_device_train_batch_size=[16],\n",
    "            per_device_eval_batch_size=[32],\n",
    "            save_steps=[0],\n",
    "            warmup_steps=[0],\n",
    "            save_total_limit=[1],\n",
    "            prediction_loss_only=[True],\n",
    "            eval_accumulation_steps=[1]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xg_cKG1D0M6p"
   },
   "source": [
    "Then the model is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "executionInfo": {
     "elapsed": 3260679,
     "status": "ok",
     "timestamp": 1619473779284,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "UUGRYmQU0MJM",
    "outputId": "fbb9b6a4-5def-4659-bbbc-3fd7bec60ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Starting grid search, totalling 6 jobs -\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 20:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.199600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.075900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 7.36 | Fitted 1 jobs out of 6. Elapsed 00:20:46 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 20:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.848700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.866900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.902600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 6.61 | Fitted 2 jobs out of 6. Elapsed 00:41:33 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 3e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 20:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.481300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.540700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.633400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.782800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 6.18 | Fitted 3 jobs out of 6. Elapsed 01:02:21 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 3e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 20:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.514400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.691400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 6.09 | Fitted 4 jobs out of 6. Elapsed 01:23:08 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 20:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.388800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.628800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 6.07 | Fitted 5 jobs out of 6. Elapsed 01:43:56 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 20:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.280400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.398500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.566900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.837400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.538800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 6.27 | Fitted 6 jobs out of 6. Elapsed 02:04:44 ------\n",
      "--- Ending grid search, totalling 6 jobs. Elapsed 02:04:44 ---\n"
     ]
    }
   ],
   "source": [
    "eu_models_params, eu_scores = grid_search_for_language_modeling(\n",
    "                    baseline_model=model,\n",
    "                    param_grid=param_grid,\n",
    "                    n_combinations=None,\n",
    "                    X=train_dataset,\n",
    "                    data_collator=data_collator,\n",
    "                    model_name='eu_bert_model',\n",
    "                    out_dir='../data/03_models/',\n",
    "                    tmp_dir='../data/03_models/tmp/'\n",
    "                    )\n",
    "\n",
    "import pickle\n",
    "pickle.dump(eu_models_params, open('../data/03_models/eu_models_params.p', 'wb'))\n",
    "pickle.dump(eu_scores, open('../data/03_models/eu_scores.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95h0iZVF0PDq"
   },
   "source": [
    "We evaluate the results obtained in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3260679,
     "status": "ok",
     "timestamp": 1619473779288,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "FL1TjxvpFKTE",
    "outputId": "ed876c8d-0ed6-4759-ce11-033ee783697c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training results: \n",
      "  - Model Perplexity: 7.36 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n",
      "  - Model Perplexity: 6.61 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n",
      "  - Model Perplexity: 6.18 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 3e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n",
      "  - Model Perplexity: 6.09 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 3e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n",
      "  - Model Perplexity: 6.07 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n",
      "  - Model Perplexity: 6.27 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 1224}\n"
     ]
    }
   ],
   "source": [
    "print('- Training results: ')\n",
    "for model_params, score in zip(eu_models_params, eu_scores):\n",
    "    print(f'  - Model Perplexity: {score:.2f} | Params: {model_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIuGliaX0R8o"
   },
   "source": [
    "And finally evaluate the results of the final best found model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "executionInfo": {
     "elapsed": 3332591,
     "status": "ok",
     "timestamp": 1619473851204,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "19ExhJ-uDjhd",
    "outputId": "ebc11214-b156-43ce-8dda-6a94ca48b0a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='612' max='612' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [612/612 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best model perplexity on test: 6.12\n"
     ]
    }
   ],
   "source": [
    "model=AutoModelForMaskedLM.from_pretrained(\"../data/03_models/eu_bert_model\")\n",
    "trainer = Trainer(\n",
    "                    model=model,\n",
    "                    eval_dataset=test_dataset,\n",
    "                    data_collator=data_collator,\n",
    "                        )\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\" Best model perplexity on test: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4no1YBo0ctS"
   },
   "source": [
    "### 2.2 Model training on United States COVID texts\n",
    "The same steps are followed for the US data model as for the European model. New training parameters need to be found as the datasets differ in size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jjFh3w_0ctT"
   },
   "source": [
    "#### Dataset build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3332984,
     "status": "ok",
     "timestamp": 1619473851601,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "riodkVMm0ctT",
    "outputId": "b56181dd-72da-4549-c2a2-c1265fa4131f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14748\n",
      "CPU times: user 3.43 s, sys: 2.05 s, total: 5.48 s\n",
      "Wall time: 2.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddiezmallo/Projects/euBERTus/.pyvenv/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import TextDataset\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('../data/03_models/tokenizer/')\n",
    "\n",
    "#tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)\n",
    "#tokenizer.add_tokens(new_tokens)\n",
    "#tokenizer.save_pretrained('../data/03_models/tokenizer')\n",
    "\n",
    "dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"../data/02_preprocessed/full_us_text.txt\",\n",
    "    block_size=128,\n",
    ")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3333185,
     "status": "ok",
     "timestamp": 1619473851805,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "Oxw6xgb10ctV",
    "outputId": "5ff75c84-12a2-4ab7-9287-8822520aaa1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n",
      "11798 2950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "print(type(train_dataset), type(test_dataset))\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10hULcze0ctV"
   },
   "source": [
    "#### Data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3333184,
     "status": "ok",
     "timestamp": 1619473851806,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "1myMCodM0ctV"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, #The tokenizer used for encoding the data.\n",
    "    mlm=True, #Whether or not to use masked language modeling. The labels are -100 for non-masked tokens and the value to predict for the masked token.\n",
    "    mlm_probability=0.15 #The probability with which to (randomly) mask tokens in the input, when mlm is set to True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5QcZ2xM0ctW"
   },
   "source": [
    "#### Train the model using the gird search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTR_UolW0ctW"
   },
   "source": [
    "The model is trained using the same parameters as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "executionInfo": {
     "elapsed": 5374035,
     "status": "ok",
     "timestamp": 1619475892660,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "5RAuCt_u0ctW",
    "outputId": "85e4c163-b8c2-40df-dc82-bca59dbd3e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Starting grid search, totalling 6 jobs -\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1881' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1881/1881 12:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.963900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.856500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 5.66 | Fitted 1 jobs out of 6. Elapsed 00:12:32 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1881' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1881/1881 12:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.565200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.528800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.565800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 4.93 | Fitted 2 jobs out of 6. Elapsed 00:25:02 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 3e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1881' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1881/1881 12:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.257400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.376500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 4.56 | Fitted 3 jobs out of 6. Elapsed 00:37:31 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 3e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1881' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1881/1881 12:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.770200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.926800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.169900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 4.49 | Fitted 4 jobs out of 6. Elapsed 00:50:02 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1881' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1881/1881 12:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.477900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.698600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.023400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 4.48 | Fitted 5 jobs out of 6. Elapsed 01:02:30 ------\n",
      "  - Training model {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1881' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1881/1881 12:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.227800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.771000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ - Perplexity: 4.63 | Fitted 6 jobs out of 6. Elapsed 01:15:01 ------\n",
      "--- Ending grid search, totalling 6 jobs. Elapsed 01:15:01 ---\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model.resize_token_embeddings(len(tokenizer)) \n",
    "\n",
    "us_models_params, us_scores = grid_search_for_language_modeling(\n",
    "                    baseline_model=model,\n",
    "                    param_grid=param_grid,\n",
    "                    n_combinations=None,\n",
    "                    X=train_dataset,\n",
    "                    data_collator=data_collator,\n",
    "                    model_name='us_bert_model',\n",
    "                    out_dir='../data/03_models/',\n",
    "                    tmp_dir='../data/03_models/tmp/'\n",
    "                    )\n",
    "\n",
    "import pickle\n",
    "pickle.dump(us_models_params, open('../data/03_models/us_models_params.p', 'wb'))\n",
    "pickle.dump(us_scores, open('../data/03_models/us_scores.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rXEihyk0ctW"
   },
   "source": [
    "We evaluate the results obtained in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5374224,
     "status": "ok",
     "timestamp": 1619475892853,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "NC8tQzc00ctW",
    "outputId": "a65da69f-4f34-4cb6-a060-1df01a791076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training results: \n",
      "  - Model Perplexity: 5.66 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n",
      "  - Model Perplexity: 4.93 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 2e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n",
      "  - Model Perplexity: 4.56 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 3e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n",
      "  - Model Perplexity: 4.49 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 3e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n",
      "  - Model Perplexity: 4.48 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'weight_decay': 0.01, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n",
      "  - Model Perplexity: 4.63 | Params: {'output_dir': '../data/03_models/trainer/', 'overwrite_output_dir': True, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'weight_decay': 0.005, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'save_steps': 0, 'warmup_steps': 0, 'save_total_limit': 1, 'prediction_loss_only': True, 'eval_accumulation_steps': 1, 'eval_steps': 738}\n"
     ]
    }
   ],
   "source": [
    "print('- Training results: ')\n",
    "for model_params, score in zip(us_models_params, us_scores):\n",
    "    print(f'  - Model Perplexity: {score:.2f} | Params: {model_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2HmOlWL0ctX"
   },
   "source": [
    "And finally evaluate the results of the final best found model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "executionInfo": {
     "elapsed": 5425030,
     "status": "ok",
     "timestamp": 1619475943664,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "0VpvwX2p0ctX",
    "outputId": "c3d9e8e7-656f-439b-e8d8-703556ed11d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='369' max='369' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [369/369 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best model perplexity on test: 4.40\n"
     ]
    }
   ],
   "source": [
    "model=AutoModelForMaskedLM.from_pretrained(\"../data/03_models/us_bert_model\")\n",
    "trainer = Trainer(\n",
    "                    model=model,\n",
    "                    eval_dataset=test_dataset,\n",
    "                    data_collator=data_collator,\n",
    "                        )\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\" Best model perplexity on test: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0caceCy_p1-"
   },
   "source": [
    "## 3. Compare the model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIQJ8ND_AEhl"
   },
   "source": [
    "Aside from looking at the training and eval losses going down, the easiest way to check whether our language model is learning anything interesting is via the `FillMaskPipeline`.\n",
    "\n",
    "Pipelines are simple wrappers around tokenizers and models, and the 'fill-mask' one will let you input a sequence containing a masked token (here, transformers.pipeline.tokenizer.mask_token) and return a list of the most probable filled sequences, with their probabilities.\n",
    "\n",
    "The predictions are compared to the predictions outputed from the base model that was used to fine tune this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 5449265,
     "status": "ok",
     "timestamp": 1619475967900,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "ltXgXyCbAJLY"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForMaskedLM, DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('../data/03_models/tokenizer/')\n",
    "\n",
    "model=AutoModelForMaskedLM.from_pretrained(\"../data/03_models/eu_bert_model\")\n",
    "\n",
    "eu_model_pipeline = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "model=AutoModelForMaskedLM.from_pretrained(\"../data/03_models/us_bert_model\")\n",
    "us_model_pipeline = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "old_model_pipeline = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1098,
     "status": "ok",
     "timestamp": 1619476097527,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "roVhxqJA8VxF",
    "outputId": "a8d0c081-bb96-4950-9c62-76eeee3ac5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'coronavirus is a very bad time', 'score': 0.17173822224140167, 'token': 2051, 'token_str': 't i m e'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'coronavirus is a very bad ;', 'score': 0.36263328790664673, 'token': 1025, 'token_str': ';'}\n",
      "OLD MODEL 0 token is            {'sequence': 'coronavirus is a very bad virus', 'score': 0.34118759632110596, 'token': 7865, 'token_str': 'v i r u s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'coronavirus is a very bad ;', 'score': 0.06552662700414658, 'token': 1025, 'token_str': ';'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'coronavirus is a very bad.', 'score': 0.19779327511787415, 'token': 1012, 'token_str': '.'}\n",
      "OLD MODEL 1 token is            {'sequence': 'coronavirus is a very bad.', 'score': 0.22734670341014862, 'token': 1012, 'token_str': '.'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'coronavirus is a very bad.', 'score': 0.0642818734049797, 'token': 1012, 'token_str': '.'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'coronavirus is a very bad thing', 'score': 0.03952965512871742, 'token': 2518, 'token_str': 't h i n g'}\n",
      "OLD MODEL 2 token is            {'sequence': 'coronavirus is a very bad ;', 'score': 0.1384032666683197, 'token': 1025, 'token_str': ';'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'coronavirus is a very bad one', 'score': 0.04539833962917328, 'token': 2028, 'token_str': 'o n e'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'coronavirus is a very bad cause', 'score': 0.037559039890766144, 'token': 3426, 'token_str': 'c a u s e'}\n",
      "OLD MODEL 3 token is            {'sequence': 'coronavirus is a very bad disease', 'score': 0.09942058473825455, 'token': 4295, 'token_str': 'd i s e a s e'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'coronavirus is a very bad pandemic', 'score': 0.040731556713581085, 'token': 30527, 'token_str': 'p a n d e m i c'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'coronavirus is a very bad habit', 'score': 0.03161458298563957, 'token': 10427, 'token_str': 'h a b i t'}\n",
      "OLD MODEL 4 token is            {'sequence': 'coronavirus is a very bad vaccine', 'score': 0.024420659989118576, 'token': 17404, 'token_str': 'v a c c i n e'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"coronavirus is a very bad {tokenizer.mask_token}\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1671,
     "status": "ok",
     "timestamp": 1619476098107,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "m39wmHjv8VxE",
    "outputId": "a31218f6-8973-4ffa-c8cd-4a96e4d4215f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'coronavirus is a very common disease', 'score': 0.4286090135574341, 'token': 2691, 'token_str': 'c o m m o n'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'coronavirus is a very common disease', 'score': 0.6938325762748718, 'token': 2691, 'token_str': 'c o m m o n'}\n",
      "OLD MODEL 0 token is            {'sequence': 'coronavirus is a very rare disease', 'score': 0.5813637375831604, 'token': 4678, 'token_str': 'r a r e'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'coronavirus is a very serious disease', 'score': 0.16115660965442657, 'token': 3809, 'token_str': 's e r i o u s'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'coronavirus is a very serious disease', 'score': 0.13249681890010834, 'token': 3809, 'token_str': 's e r i o u s'}\n",
      "OLD MODEL 1 token is            {'sequence': 'coronavirus is a very common disease', 'score': 0.23531213402748108, 'token': 2691, 'token_str': 'c o m m o n'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'coronavirus is a very rare disease', 'score': 0.04684319347143173, 'token': 4678, 'token_str': 'r a r e'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'coronavirus is a very novel disease', 'score': 0.022792847827076912, 'token': 3117, 'token_str': 'n o v e l'}\n",
      "OLD MODEL 2 token is            {'sequence': 'coronavirus is a very uncommon disease', 'score': 0.06598072499036789, 'token': 13191, 'token_str': 'u n c o m m o n'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'coronavirus is a very infectious disease', 'score': 0.03723274543881416, 'token': 16514, 'token_str': 'i n f e c t i o u s'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'coronavirus is a very rare disease', 'score': 0.015841573476791382, 'token': 4678, 'token_str': 'r a r e'}\n",
      "OLD MODEL 3 token is            {'sequence': 'coronavirus is a very serious disease', 'score': 0.037606481462717056, 'token': 3809, 'token_str': 's e r i o u s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'coronavirus is a very severe disease', 'score': 0.03660411760210991, 'token': 5729, 'token_str': 's e v e r e'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'coronavirus is a very infectious disease', 'score': 0.015052572824060917, 'token': 16514, 'token_str': 'i n f e c t i o u s'}\n",
      "OLD MODEL 4 token is            {'sequence': 'coronavirus is a very widespread disease', 'score': 0.009326490573585033, 'token': 6923, 'token_str': 'w i d e s p r e a d'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"coronavirus is a very {tokenizer.mask_token} disease\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2238,
     "status": "ok",
     "timestamp": 1619476098678,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "A9F1Gpfb8VxF",
    "outputId": "575bc057-7e14-4631-e3b1-62ded4553991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'covid is a very bad time', 'score': 0.11618148535490036, 'token': 2051, 'token_str': 't i m e'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'covid is a very bad ;', 'score': 0.2179058939218521, 'token': 1025, 'token_str': ';'}\n",
      "OLD MODEL 0 token is            {'sequence': 'covid is a very bad.', 'score': 0.19394788146018982, 'token': 1012, 'token_str': '.'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'covid is a very bad.', 'score': 0.05466793105006218, 'token': 1012, 'token_str': '.'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'covid is a very bad.', 'score': 0.1583063155412674, 'token': 1012, 'token_str': '.'}\n",
      "OLD MODEL 1 token is            {'sequence': 'covid is a very bad ;', 'score': 0.17415544390678406, 'token': 1025, 'token_str': ';'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'covid is a very bad ;', 'score': 0.03962734714150429, 'token': 1025, 'token_str': ';'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'covid is a very bad habit', 'score': 0.09749983996152878, 'token': 10427, 'token_str': 'h a b i t'}\n",
      "OLD MODEL 2 token is            {'sequence': 'covid is a very bad!', 'score': 0.15606757998466492, 'token': 999, 'token_str': '!'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'covid is a very bad thing', 'score': 0.03328334912657738, 'token': 2518, 'token_str': 't h i n g'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'covid is a very bad boy', 'score': 0.03458205983042717, 'token': 2879, 'token_str': 'b o y'}\n",
      "OLD MODEL 3 token is            {'sequence': 'covid is a very bad boy', 'score': 0.031214553862810135, 'token': 2879, 'token_str': 'b o y'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'covid is a very bad business', 'score': 0.030844038352370262, 'token': 2449, 'token_str': 'b u s i n e s s'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'covid is a very bad thing', 'score': 0.03082716278731823, 'token': 2518, 'token_str': 't h i n g'}\n",
      "OLD MODEL 4 token is            {'sequence': 'covid is a very bad character', 'score': 0.020547637715935707, 'token': 2839, 'token_str': 'c h a r a c t e r'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"covid is a very bad {tokenizer.mask_token}\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2749,
     "status": "ok",
     "timestamp": 1619476099193,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "OijIQdA68VxF",
    "outputId": "a03619aa-cf9a-416d-8060-0ce25ef2e995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'covid is a very common disease', 'score': 0.3215981125831604, 'token': 2691, 'token_str': 'c o m m o n'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'covid is a very common disease', 'score': 0.6336857676506042, 'token': 2691, 'token_str': 'c o m m o n'}\n",
      "OLD MODEL 0 token is            {'sequence': 'covid is a very rare disease', 'score': 0.7391716837882996, 'token': 4678, 'token_str': 'r a r e'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'covid is a very infectious disease', 'score': 0.09421249479055405, 'token': 16514, 'token_str': 'i n f e c t i o u s'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'covid is a very serious disease', 'score': 0.1463167667388916, 'token': 3809, 'token_str': 's e r i o u s'}\n",
      "OLD MODEL 1 token is            {'sequence': 'covid is a very common disease', 'score': 0.13259394466876984, 'token': 2691, 'token_str': 'c o m m o n'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'covid is a very rare disease', 'score': 0.08256250619888306, 'token': 4678, 'token_str': 'r a r e'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'covid is a very rare disease', 'score': 0.051978904753923416, 'token': 4678, 'token_str': 'r a r e'}\n",
      "OLD MODEL 2 token is            {'sequence': 'covid is a very uncommon disease', 'score': 0.03844136372208595, 'token': 13191, 'token_str': 'u n c o m m o n'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'covid is a very serious disease', 'score': 0.0813407301902771, 'token': 3809, 'token_str': 's e r i o u s'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'covid is a very similar disease', 'score': 0.017908239737153053, 'token': 2714, 'token_str': 's i m i l a r'}\n",
      "OLD MODEL 3 token is            {'sequence': 'covid is a very serious disease', 'score': 0.022446056827902794, 'token': 3809, 'token_str': 's e r i o u s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'covid is a very important disease', 'score': 0.03876752406358719, 'token': 2590, 'token_str': 'i m p o r t a n t'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'covid is a very infectious disease', 'score': 0.016012469306588173, 'token': 16514, 'token_str': 'i n f e c t i o u s'}\n",
      "OLD MODEL 4 token is            {'sequence': 'covid is a very variable disease', 'score': 0.0037340836133807898, 'token': 8023, 'token_str': 'v a r i a b l e'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"covid is a very {tokenizer.mask_token} disease\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3070,
     "status": "ok",
     "timestamp": 1619476099517,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "Pfs7SI7E9Ei3",
    "outputId": "31d6a3ed-2a62-47a6-e316-f9150d68323c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'it is a disease', 'score': 0.14260460436344147, 'token': 2009, 'token_str': 'i t'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'it is a disease', 'score': 0.04115577042102814, 'token': 2009, 'token_str': 'i t'}\n",
      "OLD MODEL 0 token is            {'sequence': 'tuberculosis is a disease', 'score': 0.08622989058494568, 'token': 15877, 'token_str': 't u b e r c u l o s i s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'this is a disease', 'score': 0.09274052828550339, 'token': 2023, 'token_str': 't h i s'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'tuberculosis is a disease', 'score': 0.026136085391044617, 'token': 15877, 'token_str': 't u b e r c u l o s i s'}\n",
      "OLD MODEL 1 token is            {'sequence': 'malaria is a disease', 'score': 0.03631953150033951, 'token': 19132, 'token_str': 'm a l a r i a'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'which is a disease', 'score': 0.07250746339559555, 'token': 2029, 'token_str': 'w h i c h'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'obesity is a disease', 'score': 0.02101035974919796, 'token': 24552, 'token_str': 'o b e s i t y'}\n",
      "OLD MODEL 2 token is            {'sequence': 'cholera is a disease', 'score': 0.028907811269164085, 'token': 25916, 'token_str': 'c h o l e r a'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'and is a disease', 'score': 0.04892382398247719, 'token': 1998, 'token_str': 'a n d'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'tb is a disease', 'score': 0.015135323628783226, 'token': 26419, 'token_str': 't b'}\n",
      "OLD MODEL 3 token is            {'sequence': 'diabetes is a disease', 'score': 0.026251696050167084, 'token': 14671, 'token_str': 'd i a b e t e s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'virus is a disease', 'score': 0.026556041091680527, 'token': 7865, 'token_str': 'v i r u s'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'there is a disease', 'score': 0.013566064648330212, 'token': 2045, 'token_str': 't h e r e'}\n",
      "OLD MODEL 4 token is            {'sequence': 'obesity is a disease', 'score': 0.024895397946238518, 'token': 24552, 'token_str': 'o b e s i t y'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"{tokenizer.mask_token} is a disease\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3783,
     "status": "ok",
     "timestamp": 1619476100234,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "qbXoYXCd9JVT",
    "outputId": "c811dad7-96f5-41f7-9231-cc8e7aa9b6c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'the consequences of the coronavirus pandemic are very serious', 'score': 0.5420258045196533, 'token': 8465, 'token_str': 'c o n s e q u e n c e s'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'the effects of the coronavirus pandemic are very serious', 'score': 0.4934997260570526, 'token': 3896, 'token_str': 'e f f e c t s'}\n",
      "OLD MODEL 0 token is            {'sequence': 'the symptoms of the coronavirus pandemic are very serious', 'score': 0.29923003911972046, 'token': 8030, 'token_str': 's y m p t o m s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'the effects of the coronavirus pandemic are very serious', 'score': 0.385225772857666, 'token': 3896, 'token_str': 'e f f e c t s'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'the impacts of the coronavirus pandemic are very serious', 'score': 0.13947957754135132, 'token': 14670, 'token_str': 'i m p a c t s'}\n",
      "OLD MODEL 1 token is            {'sequence': 'the effects of the coronavirus pandemic are very serious', 'score': 0.19865989685058594, 'token': 3896, 'token_str': 'e f f e c t s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'the impacts of the coronavirus pandemic are very serious', 'score': 0.028416510671377182, 'token': 14670, 'token_str': 'i m p a c t s'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'the consequences of the coronavirus pandemic are very serious', 'score': 0.13756802678108215, 'token': 8465, 'token_str': 'c o n s e q u e n c e s'}\n",
      "OLD MODEL 2 token is            {'sequence': 'the risks of the coronavirus pandemic are very serious', 'score': 0.12781693041324615, 'token': 10831, 'token_str': 'r i s k s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'the implications of the coronavirus pandemic are very serious', 'score': 0.023345444351434708, 'token': 13494, 'token_str': 'i m p l i c a t i o n s'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'the implications of the coronavirus pandemic are very serious', 'score': 0.06550318747758865, 'token': 13494, 'token_str': 'i m p l i c a t i o n s'}\n",
      "OLD MODEL 3 token is            {'sequence': 'the consequences of the coronavirus pandemic are very serious', 'score': 0.10717489570379257, 'token': 8465, 'token_str': 'c o n s e q u e n c e s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'the risks of the coronavirus pandemic are very serious', 'score': 0.00785654317587614, 'token': 10831, 'token_str': 'r i s k s'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'the results of the coronavirus pandemic are very serious', 'score': 0.05551331862807274, 'token': 3463, 'token_str': 'r e s u l t s'}\n",
      "OLD MODEL 4 token is            {'sequence': 'the complications of the coronavirus pandemic are very serious', 'score': 0.08627314120531082, 'token': 12763, 'token_str': 'c o m p l i c a t i o n s'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"The {tokenizer.mask_token} of the coronavirus pandemic are very serious\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4430,
     "status": "ok",
     "timestamp": 1619476100885,
     "user": {
      "displayName": "Daniel Díez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLEy0o7LWx6R7BMbWyhyGTGiCURLs_CtPEbpxL8P4=s64",
      "userId": "04428453110580774456"
     },
     "user_tz": -120
    },
    "id": "sZujADpu9S_z",
    "outputId": "1c896a8d-590f-4e02-d2b2-a9987e41db8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'the consequences of the earthquake are very serious', 'score': 0.39475271105766296, 'token': 8372, 'token_str': 'e a r t h q u a k e'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'the consequences of the disaster are very serious', 'score': 0.1754169911146164, 'token': 7071, 'token_str': 'd i s a s t e r'}\n",
      "OLD MODEL 0 token is            {'sequence': 'the consequences of the accident are very serious', 'score': 0.08996063470840454, 'token': 4926, 'token_str': 'a c c i d e n t'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'the consequences of the pandemic are very serious', 'score': 0.12387777119874954, 'token': 30527, 'token_str': 'p a n d e m i c'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'the consequences of the accident are very serious', 'score': 0.09676043689250946, 'token': 4926, 'token_str': 'a c c i d e n t'}\n",
      "OLD MODEL 1 token is            {'sequence': 'the consequences of the earthquake are very serious', 'score': 0.05031542852520943, 'token': 8372, 'token_str': 'e a r t h q u a k e'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'the consequences of the disaster are very serious', 'score': 0.10149619728326797, 'token': 7071, 'token_str': 'd i s a s t e r'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'the consequences of the flood are very serious', 'score': 0.051630400121212006, 'token': 7186, 'token_str': 'f l o o d'}\n",
      "OLD MODEL 2 token is            {'sequence': 'the consequences of the disaster are very serious', 'score': 0.03415784239768982, 'token': 7071, 'token_str': 'd i s a s t e r'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'the consequences of the crisis are very serious', 'score': 0.09968487918376923, 'token': 5325, 'token_str': 'c r i s i s'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'the consequences of the fire are very serious', 'score': 0.02664901502430439, 'token': 2543, 'token_str': 'f i r e'}\n",
      "OLD MODEL 3 token is            {'sequence': 'the consequences of the incident are very serious', 'score': 0.014941252768039703, 'token': 5043, 'token_str': 'i n c i d e n t'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'the consequences of the accident are very serious', 'score': 0.02674679271876812, 'token': 4926, 'token_str': 'a c c i d e n t'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'the consequences of the failure are very serious', 'score': 0.024734504520893097, 'token': 4945, 'token_str': 'f a i l u r e'}\n",
      "OLD MODEL 4 token is            {'sequence': 'the consequences of the crash are very serious', 'score': 0.014047699049115181, 'token': 5823, 'token_str': 'c r a s h'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"the consequences of the {tokenizer.mask_token} are very serious\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'coronavirus disease is an infectious disease caused by a.', 'score': 0.23049484193325043, 'token': 1012, 'token_str': '.'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'coronavirus disease is an infectious disease caused by a.', 'score': 0.2763156294822693, 'token': 1012, 'token_str': '.'}\n",
      "OLD MODEL 0 token is            {'sequence': 'coronavirus disease is an infectious disease caused by a.', 'score': 0.4726460874080658, 'token': 1012, 'token_str': '.'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'coronavirus disease is an infectious disease caused by a virus', 'score': 0.1717226505279541, 'token': 7865, 'token_str': 'v i r u s'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'coronavirus disease is an infectious disease caused by a novel', 'score': 0.17340105772018433, 'token': 3117, 'token_str': 'n o v e l'}\n",
      "OLD MODEL 1 token is            {'sequence': 'coronavirus disease is an infectious disease caused by a virus', 'score': 0.08265344053506851, 'token': 7865, 'token_str': 'v i r u s'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'coronavirus disease is an infectious disease caused by a disease', 'score': 0.11758947372436523, 'token': 4295, 'token_str': 'd i s e a s e'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'coronavirus disease is an infectious disease caused by a virus', 'score': 0.15260049700737, 'token': 7865, 'token_str': 'v i r u s'}\n",
      "OLD MODEL 2 token is            {'sequence': 'coronavirus disease is an infectious disease caused by a ;', 'score': 0.07256146520376205, 'token': 1025, 'token_str': ';'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'coronavirus disease is an infectious disease caused by a coronavirus', 'score': 0.06435559689998627, 'token': 30524, 'token_str': 'c o r o n a v i r u s'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'coronavirus disease is an infectious disease caused by a disease', 'score': 0.14834550023078918, 'token': 4295, 'token_str': 'd i s e a s e'}\n",
      "OLD MODEL 3 token is            {'sequence': 'coronavirus disease is an infectious disease caused by a viral', 'score': 0.056607749313116074, 'token': 13434, 'token_str': 'v i r a l'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'coronavirus disease is an infectious disease caused by a pandemic', 'score': 0.06209920719265938, 'token': 30527, 'token_str': 'p a n d e m i c'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'coronavirus disease is an infectious disease caused by a ;', 'score': 0.028607163578271866, 'token': 1025, 'token_str': ';'}\n",
      "OLD MODEL 4 token is            {'sequence': 'coronavirus disease is an infectious disease caused by a corona', 'score': 0.0405053049325943, 'token': 21887, 'token_str': 'c o r o n a'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"coronavirus disease is an infectious disease caused by a {tokenizer.mask_token}\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUROPEAN MODEL 0 token is       {'sequence': 'the covid virus spreads primarily through the', 'score': 0.136428102850914, 'token': 1996, 'token_str': 't h e'}\n",
      "UNITED STATES MODEL 0 token is  {'sequence': 'the covid virus spreads primarily through.', 'score': 0.10988763719797134, 'token': 1012, 'token_str': '.'}\n",
      "OLD MODEL 0 token is            {'sequence': 'the covid virus spreads primarily through :', 'score': 0.2401067316532135, 'token': 1024, 'token_str': ':'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 1 token is       {'sequence': 'the covid virus spreads primarily through.', 'score': 0.12120738625526428, 'token': 1012, 'token_str': '.'}\n",
      "UNITED STATES MODEL 1 token is  {'sequence': 'the covid virus spreads primarily through ;', 'score': 0.10381394624710083, 'token': 1025, 'token_str': ';'}\n",
      "OLD MODEL 1 token is            {'sequence': 'the covid virus spreads primarily through.', 'score': 0.17415806651115417, 'token': 1012, 'token_str': '.'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 2 token is       {'sequence': 'the covid virus spreads primarily through :', 'score': 0.0736658051609993, 'token': 1024, 'token_str': ':'}\n",
      "UNITED STATES MODEL 2 token is  {'sequence': 'the covid virus spreads primarily through :', 'score': 0.1033090204000473, 'token': 1024, 'token_str': ':'}\n",
      "OLD MODEL 2 token is            {'sequence': 'the covid virus spreads primarily through ;', 'score': 0.1598534733057022, 'token': 1025, 'token_str': ';'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 3 token is       {'sequence': 'the covid virus spreads primarily through ;', 'score': 0.03886747360229492, 'token': 1025, 'token_str': ';'}\n",
      "UNITED STATES MODEL 3 token is  {'sequence': 'the covid virus spreads primarily through the', 'score': 0.06066581606864929, 'token': 1996, 'token_str': 't h e'}\n",
      "OLD MODEL 3 token is            {'sequence': 'the covid virus spreads primarily through bacteria', 'score': 0.03402412310242653, 'token': 10327, 'token_str': 'b a c t e r i a'}\n",
      "--------------------------------\n",
      "EUROPEAN MODEL 4 token is       {'sequence': 'the covid virus spreads primarily through a', 'score': 0.02871589921414852, 'token': 1037, 'token_str': 'a'}\n",
      "UNITED STATES MODEL 4 token is  {'sequence': 'the covid virus spreads primarily through covid', 'score': 0.04964155703783035, 'token': 30522, 'token_str': 'c o v i d'}\n",
      "OLD MODEL 4 token is            {'sequence': 'the covid virus spreads primarily through viral', 'score': 0.019860606640577316, 'token': 13434, 'token_str': 'v i r a l'}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequence = f\"the covid virus spreads primarily through {tokenizer.mask_token}\"\n",
    "eu_model_pipeline_results = eu_model_pipeline(sequence)\n",
    "us_model_pipeline_results = us_model_pipeline(sequence)\n",
    "old_model_pipeline_results = old_model_pipeline(sequence)\n",
    "\n",
    "for idx,(eu_prediction, us_prediction, old_prediction) in enumerate(zip(eu_model_pipeline_results, us_model_pipeline_results, old_model_pipeline_results)):\n",
    "    print(f'EUROPEAN MODEL {idx} token is       {eu_prediction}')\n",
    "    print(f'UNITED STATES MODEL {idx} token is  {us_prediction}')\n",
    "    print(f'OLD MODEL {idx} token is            {old_prediction}')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text(sequence, pipeline, steps=15):\n",
    "    for step in range(steps):\n",
    "        prediction_sequence = f'{sequence} {tokenizer.mask_token}'\n",
    "        results = pipeline(prediction_sequence)\n",
    "        token = results[0]['token_str']\n",
    "        sequence = f'{sequence}{token}'\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the covid virus spreads primarily through\n",
      "the covid virus spreads primarily throught h ev i r u s.c.c.c.c.c.c.\n",
      "--------------------------------\n",
      "the covid virus spreads primarily through\n",
      "the covid virus spreads primarily through...............\n",
      "--------------------------------\n",
      "the covid virus spreads primarily through\n",
      "the covid virus spreads primarily through:..............\n"
     ]
    }
   ],
   "source": [
    "old_sequence = \"the covid virus spreads primarily through\" \n",
    "new_sequence = create_text(old_sequence, eu_model_pipeline, steps=15)   \n",
    "print(f'{old_sequence}\\n{new_sequence}')\n",
    "print('--------------------------------')\n",
    "new_sequence = create_text(old_sequence, us_model_pipeline, steps=15)   \n",
    "print(f'{old_sequence}\\n{new_sequence}')\n",
    "print('--------------------------------')\n",
    "new_sequence = create_text(old_sequence, old_model_pipeline, steps=15)   \n",
    "print(f'{old_sequence}\\n{new_sequence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The consequenes of the pandemic need to be\n",
      "The consequenes of the pandemic need to bea d d r e s s e del ar# # r of;4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4\n",
      "--------------------------------\n",
      "The consequenes of the pandemic need to be\n",
      "The consequenes of the pandemic need to beo v e r c o m ew.i.op.4 5.1.32.1.1.23...................\n",
      "--------------------------------\n",
      "The consequenes of the pandemic need to be\n",
      "The consequenes of the pandemic need to be.\"......\".......\".......................\n"
     ]
    }
   ],
   "source": [
    "old_sequence = \"The consequenes of the pandemic need to be\" \n",
    "new_sequence = create_text(old_sequence, eu_model_pipeline, steps=40)   \n",
    "print(f'{old_sequence}\\n{new_sequence}')\n",
    "print('--------------------------------')\n",
    "new_sequence = create_text(old_sequence, us_model_pipeline, steps=40)   \n",
    "print(f'{old_sequence}\\n{new_sequence}')\n",
    "print('--------------------------------')\n",
    "new_sequence = create_text(old_sequence, old_model_pipeline, steps=40)   \n",
    "print(f'{old_sequence}\\n{new_sequence}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "03_training_ModelForLM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "euBERTus_env",
   "language": "python",
   "name": "eubertus_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "5e6813dbf69670d6d3886595d9cfd7f636152ce64500f8f1b519576bcad72771"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
